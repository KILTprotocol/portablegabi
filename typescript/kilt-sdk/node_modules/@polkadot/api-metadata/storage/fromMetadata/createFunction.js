"use strict";

var _interopRequireDefault = require("@babel/runtime/helpers/interopRequireDefault");

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = createFunction;

var _defineProperty2 = _interopRequireDefault(require("@babel/runtime/helpers/defineProperty"));

var _codec = require("@polkadot/types/codec");

var _Storage = require("@polkadot/types/Metadata/v8/Storage");

var _util = require("@polkadot/util");

var _getHasher = _interopRequireDefault(require("./getHasher"));

function ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }

function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(source, true).forEach(function (key) { (0, _defineProperty2.default)(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(source).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }

const NULL_HASHER = value => value; // with the prefix, method & options, create both the string & raw keys


function createKeys(_ref, options) {
  let {
    method,
    prefix
  } = _ref;
  const stringKey = options.key ? options.key : "".concat(prefix, " ").concat(method);
  return [stringKey, (0, _util.stringToU8a)(stringKey)];
} // get the hashers, the base (and  in the case of DoubleMap), the second key


function getHashers(_ref2) {
  let {
    meta: {
      type
    }
  } = _ref2;

  if (type.isDoubleMap) {
    return [(0, _getHasher.default)(type.asDoubleMap.hasher), (0, _getHasher.default)(type.asDoubleMap.key2Hasher)];
  } else if (type.isMap) {
    return [(0, _getHasher.default)(type.asMap.hasher)];
  } // the default


  return [(0, _getHasher.default)()];
} // create a key for a DoubleMap type


function createKeyDoubleMap(_ref3, rawKey, args, _ref4) {
  let {
    meta: {
      name,
      type
    }
  } = _ref3;
  let [hasher, key2Hasher] = _ref4;
  // since we are passing an almost-unknown through, trust, but verify
  (0, _util.assert)(Array.isArray(args) && !(0, _util.isUndefined)(args[0]) && !(0, _util.isNull)(args[0]) && !(0, _util.isUndefined)(args[1]) && !(0, _util.isNull)(args[1]), "".concat(name, " is a DoubleMap and requires two arguments"));
  const [key1, key2] = args;
  const type1 = type.asDoubleMap.key1.toString();
  const type2 = type.asDoubleMap.key2.toString();
  const param1Encoded = (0, _util.u8aConcat)(rawKey, (0, _codec.createTypeUnsafe)(type1, [key1]).toU8a(true));
  const param1Hashed = hasher(param1Encoded); // If this fails it means the getHashers function failed - and we have much bigger issues

  const param2Hashed = key2Hasher((0, _codec.createTypeUnsafe)(type2, [key2]).toU8a(true)); // as per createKey, always add the length prefix (underlying it is Bytes)

  return _codec.Compact.addLengthPrefix((0, _util.u8aConcat)(param1Hashed, param2Hashed));
} // create a key for either a map or a plain value


function createKey(_ref5, rawKey, arg, hasher) {
  let {
    meta: {
      name,
      type
    }
  } = _ref5;
  let key = rawKey;

  if (type.isMap) {
    (0, _util.assert)(!(0, _util.isUndefined)(arg) && !(0, _util.isNull)(arg), "".concat(name, " is a Map and requires one argument"));
    const mapType = type.asMap.key.toString();
    const param = (0, _codec.createTypeUnsafe)(mapType, [arg]).toU8a();
    key = (0, _util.u8aConcat)(key, param);
  } // StorageKey is a Bytes, so is length-prefixed


  return _codec.Compact.addLengthPrefix(hasher(key));
} // attach the metadata to expsnd to a StorageFunction


function expandWithMeta(_ref6, storageFn) {
  let {
    meta,
    method,
    prefix,
    section
  } = _ref6;
  storageFn.meta = meta;
  storageFn.method = (0, _util.stringLowerFirst)(method);
  storageFn.prefix = prefix;
  storageFn.section = section; // explicitly add the actual method in the toJSON, this gets used to determine caching and without it
  // instances (e.g. collective) will not work since it is only matched on param meta

  storageFn.toJSON = () => _objectSpread({}, meta.toJSON(), {
    storage: {
      method,
      prefix,
      section
    }
  });

  return storageFn;
} // attch the head key hashing for linked maps


function extendLinkedMap(_ref7, storageFn, stringKey, hasher) {
  let {
    meta: {
      documentation,
      name,
      type
    }
  } = _ref7;
  const headHash = new _codec.U8a(hasher("head of ".concat(stringKey)));

  const headFn = () => headHash; // metadata with a fallback value using the type of the key, the normal
  // meta fallback only applies to actual entry values, create one for head


  headFn.meta = new _Storage.StorageEntryMetadata({
    name,
    modifier: (0, _codec.createType)('StorageEntryModifierLatest', 1),
    // required
    type: new _Storage.StorageEntryType((0, _codec.createType)('PlainTypeLatest', type.asMap.key), 0),
    fallback: (0, _codec.createType)('Bytes', (0, _codec.createTypeUnsafe)(type.asMap.key.toString()).toHex()),
    documentation
  }); // here we pass the section/method through as well - these are not on
  // the function itself, so specify these explicitly to the constructor

  storageFn.headKey = (0, _codec.createType)('StorageKey', headFn, {
    method: storageFn.method,
    section: "head of ".concat(storageFn.section)
  });
  return storageFn;
}
/**
 * From the schema of a function in the module's storage, generate the function
 * that will return the correct storage key.
 *
 * @param item - The function's definition schema to create the function from.
 * The schema is taken from state_getMetadata.
 * @param options - Additional options when creating the function. These options
 * are not known at runtime (from state_getMetadata), they need to be supplied
 * by us manually at compile time.
 */


function createFunction(item) {
  let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  const {
    meta: {
      type
    }
  } = item;
  const [stringKey, rawKey] = createKeys(item, options);
  const [hasher, key2Hasher] = getHashers(item); // Can only have zero or one argument:
  //   - storage.balances.freeBalance(address)
  //   - storage.timestamp.blockPeriod()
  // For doublemap queries the params is passed in as an tuple, [key1, key2]

  const _storageFn = arg => type.isDoubleMap ? createKeyDoubleMap(item, rawKey, arg, [hasher, key2Hasher]) : createKey(item, rawKey, arg, options.skipHashing ? NULL_HASHER : hasher);

  const storageFn = expandWithMeta(item, _storageFn);

  if (type.isMap && type.asMap.linked.isTrue) {
    extendLinkedMap(item, storageFn, stringKey, hasher);
  }

  return storageFn;
}